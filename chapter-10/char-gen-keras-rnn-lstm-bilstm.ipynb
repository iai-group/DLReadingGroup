{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ansatt/vsetty/miniconda2/envs/keras-conda-27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, SimpleRNN, Activation, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "#only occupy 50% of memory on the GPU\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "#config.gpu_options.allow_growth = True\n",
    "tf.Session(config=config)\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  86950\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "def prepareData():\n",
    "    # load ascii text and covert to lowercase\n",
    "    filename = \"life-of-brian.txt\"\n",
    "    raw_text = open(filename).read()\n",
    "    raw_text = raw_text.lower()\n",
    "    # create mapping of unique chars to integers\n",
    "    chars = sorted(list(set(raw_text)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "    # summarize the loaded data\n",
    "    n_chars = len(raw_text)\n",
    "    n_vocab = len(chars)\n",
    "    seq_length = 100\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, n_chars - seq_length, 1):\n",
    "        seq_in = raw_text[i:i + seq_length]\n",
    "        seq_out = raw_text[i + seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "    n_patterns = len(dataX)\n",
    "    print \"Total Patterns: \", n_patterns\n",
    "    # reshape X to be [samples, time steps, features]\n",
    "    X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "    # normalize\n",
    "    X = X / float(n_vocab)\n",
    "    # one hot encode the output variable\n",
    "    y = np_utils.to_categorical(dataY)\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    # pick a random seed\n",
    "    return X, y, dataX, dataY, char_to_int, int_to_char, n_vocab\n",
    "\n",
    "X, y, dataX, dataY, char_to_int, int_to_char, n_vocab = prepareData()\n",
    "def generateText(model, filename, seedpattern):\n",
    "    model.load_weights(filename)\n",
    "#     model.summary()\n",
    "    # generate characters\n",
    "    for i in range(1000):\n",
    "        x = numpy.reshape(seedpattern, (1, len(seedpattern), 1))\n",
    "        x = x / float(n_vocab)\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_char[index]\n",
    "        seq_in = [int_to_char[value] for value in seedpattern]\n",
    "        sys.stdout.write(result)\n",
    "        seedpattern.append(index)\n",
    "        seedpattern = seedpattern[1:len(seedpattern)]\n",
    "    print \"\\nDone.\"\n",
    "    \n",
    "def getIntVals(strseedpattern):\n",
    "    return [char_to_int[char] for char in strseedpattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ansatt/vsetty/miniconda2/envs/keras-conda-27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1029: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/ansatt/vsetty/miniconda2/envs/keras-conda-27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1108: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# define the SimpleRNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=filename+\"weights-rnn-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 3.1251Epoch 00000: loss improved from inf to 3.12509, saving model to montypython/life-of-brian.txtweights-rnn-00-3.1251.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 3.1251    \n",
      "Epoch 2/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 3.0222Epoch 00001: loss improved from 3.12509 to 3.02193, saving model to montypython/life-of-brian.txtweights-rnn-01-3.0219.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 3.0219    \n",
      "Epoch 3/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.9882Epoch 00002: loss improved from 3.02193 to 2.98823, saving model to montypython/life-of-brian.txtweights-rnn-02-2.9882.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.9882    \n",
      "Epoch 4/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.9541Epoch 00003: loss improved from 2.98823 to 2.95391, saving model to montypython/life-of-brian.txtweights-rnn-03-2.9539.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.9539    \n",
      "Epoch 5/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.9238Epoch 00004: loss improved from 2.95391 to 2.92370, saving model to montypython/life-of-brian.txtweights-rnn-04-2.9237.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.9237    \n",
      "Epoch 6/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.8975Epoch 00005: loss improved from 2.92370 to 2.89759, saving model to montypython/life-of-brian.txtweights-rnn-05-2.8976.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.8976    \n",
      "Epoch 7/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.8742Epoch 00006: loss improved from 2.89759 to 2.87415, saving model to montypython/life-of-brian.txtweights-rnn-06-2.8742.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.8742    \n",
      "Epoch 8/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.8521Epoch 00007: loss improved from 2.87415 to 2.85217, saving model to montypython/life-of-brian.txtweights-rnn-07-2.8522.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.8522    \n",
      "Epoch 9/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.8333Epoch 00008: loss improved from 2.85217 to 2.83325, saving model to montypython/life-of-brian.txtweights-rnn-08-2.8333.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.8333    \n",
      "Epoch 10/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.8138Epoch 00009: loss improved from 2.83325 to 2.81377, saving model to montypython/life-of-brian.txtweights-rnn-09-2.8138.hdf5\n",
      "86950/86950 [==============================] - 24s - loss: 2.8138    \n",
      "Epoch 11/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.7978Epoch 00010: loss improved from 2.81377 to 2.79788, saving model to montypython/life-of-brian.txtweights-rnn-10-2.7979.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.7979    \n",
      "Epoch 12/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.7795Epoch 00011: loss improved from 2.79788 to 2.77943, saving model to montypython/life-of-brian.txtweights-rnn-11-2.7794.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.7794    \n",
      "Epoch 13/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.7660Epoch 00012: loss improved from 2.77943 to 2.76593, saving model to montypython/life-of-brian.txtweights-rnn-12-2.7659.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.7659    \n",
      "Epoch 14/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.7515Epoch 00013: loss improved from 2.76593 to 2.75155, saving model to montypython/life-of-brian.txtweights-rnn-13-2.7516.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.7516    \n",
      "Epoch 15/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.7374Epoch 00014: loss improved from 2.75155 to 2.73722, saving model to montypython/life-of-brian.txtweights-rnn-14-2.7372.hdf5\n",
      "86950/86950 [==============================] - 25s - loss: 2.7372    \n",
      "Epoch 16/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.7400Epoch 00015: loss did not improve\n",
      "86950/86950 [==============================] - 25s - loss: 2.7400    \n",
      "Epoch 17/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.7133Epoch 00016: loss improved from 2.73722 to 2.71317, saving model to montypython/life-of-brian.txtweights-rnn-16-2.7132.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.7132    \n",
      "Epoch 18/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.6949Epoch 00017: loss improved from 2.71317 to 2.69482, saving model to montypython/life-of-brian.txtweights-rnn-17-2.6948.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.6948    \n",
      "Epoch 19/20\n",
      "86784/86950 [============================>.] - ETA: 0s - loss: 2.6812Epoch 00018: loss improved from 2.69482 to 2.68152, saving model to montypython/life-of-brian.txtweights-rnn-18-2.6815.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.6815    \n",
      "Epoch 20/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.6692Epoch 00019: loss improved from 2.68152 to 2.66914, saving model to montypython/life-of-brian.txtweights-rnn-19-2.6691.hdf5\n",
      "86950/86950 [==============================] - 26s - loss: 2.6691    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60f81a1210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, nb_epoch=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \n",
      "brian: whl \n",
      "aen boi ta  aoian: whe  ae ao aoo toe toe  arian: whl \n",
      "aen soe teee  ser.\n",
      "mend  aa aad  aoean: whe \n",
      "ae a mene  aeiau  oh  hee  ae aoe noe toe sere the  aoian: whl \n",
      "aen noi te toe toe teet toe soete  soe \n",
      "aet noi te toe toue the soee ti tee  ao ane tou  arian: whl \n",
      "aen soe teee  ber boi toe toe \n",
      "arian: whl \n",
      "aen soe teee  ser.\n",
      "mend  aa aad  aoean: whe \n",
      "ae a mene  aeiau  oh  hee  ae aoe noe toe sere the  aoian: whl \n",
      "aen noi te toe toe teet toe soete  soe \n",
      "aet noi te toe toue the soee ti tee  ao ane tou  arian: whl \n",
      "aen soe teee  ber boi toe toe \n",
      "arian: whl \n",
      "aen soe teee  ser.\n",
      "mend  aa aad  aoean: whe \n",
      "ae a mene  aeiau  oh  hee  ae aoe noe toe sere the  aoian: whl \n",
      "aen noi te toe toe teet toe soete  soe \n",
      "aet noi te toe toue the soee ti tee  ao ane tou  arian: whl \n",
      "aen soe teee  ber boi toe toe \n",
      "arian: whl \n",
      "aen soe teee  ser.\n",
      "mend  aa aad  aoean: whe \n",
      "ae a mene  aeiau  oh  hee  ae aoe noe toe sere the  aoian: whl \n",
      "aen noi te toe toe teet toe soete  soe \n",
      "aet noi te toe toue the s\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rnnmodel = Sequential()\n",
    "rnnmodel.add(SimpleRNN(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "rnnmodel.add(Dropout(0.2))\n",
    "rnnmodel.add(Dense(y.shape[1], activation='softmax'))\n",
    "# X, y, dataX, dataY, char_to_int, int_to_char = prepareData()\n",
    "strseedpattern = \"all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \"\n",
    "print \"seed: \" + strseedpattern\n",
    "generateText(rnnmodel, \"life-of-brian.txtweights-rnn-19-2.6691.hdf5\", getIntVals(strseedpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the LSTM model\n",
    "lstmmodel = Sequential()\n",
    "lstmmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "lstmmodel.add(Dropout(0.2))\n",
    "lstmmodel.add(Dense(y.shape[1], activation='softmax'))\n",
    "lstmmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "lstmmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=filename+\"weights-lstm-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 3.1238Epoch 00000: loss improved from inf to 3.12359, saving model to montypython/life-of-brian.txtweights-lstm-00-3.1236.hdf5\n",
      "86950/86950 [==============================] - 108s - loss: 3.1236   \n",
      "Epoch 2/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.9583Epoch 00001: loss improved from 3.12359 to 2.95828, saving model to montypython/life-of-brian.txtweights-lstm-01-2.9583.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.9583   \n",
      "Epoch 3/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.8757Epoch 00002: loss improved from 2.95828 to 2.87583, saving model to montypython/life-of-brian.txtweights-lstm-02-2.8758.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.8758   \n",
      "Epoch 4/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.8059Epoch 00003: loss improved from 2.87583 to 2.80590, saving model to montypython/life-of-brian.txtweights-lstm-03-2.8059.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.8059   \n",
      "Epoch 5/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.7327Epoch 00004: loss improved from 2.80590 to 2.73274, saving model to montypython/life-of-brian.txtweights-lstm-04-2.7327.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.7327   \n",
      "Epoch 6/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.6655Epoch 00005: loss improved from 2.73274 to 2.66555, saving model to montypython/life-of-brian.txtweights-lstm-05-2.6656.hdf5\n",
      "86950/86950 [==============================] - 105s - loss: 2.6656   \n",
      "Epoch 7/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.6033Epoch 00006: loss improved from 2.66555 to 2.60333, saving model to montypython/life-of-brian.txtweights-lstm-06-2.6033.hdf5\n",
      "86950/86950 [==============================] - 106s - loss: 2.6033   \n",
      "Epoch 8/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.5458Epoch 00007: loss improved from 2.60333 to 2.54576, saving model to montypython/life-of-brian.txtweights-lstm-07-2.5458.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.5458   \n",
      "Epoch 9/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.4936Epoch 00008: loss improved from 2.54576 to 2.49350, saving model to montypython/life-of-brian.txtweights-lstm-08-2.4935.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.4935   \n",
      "Epoch 10/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.4458Epoch 00009: loss improved from 2.49350 to 2.44582, saving model to montypython/life-of-brian.txtweights-lstm-09-2.4458.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.4458   \n",
      "Epoch 11/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.4433Epoch 00010: loss improved from 2.44582 to 2.44335, saving model to montypython/life-of-brian.txtweights-lstm-10-2.4433.hdf5\n",
      "86950/86950 [==============================] - 106s - loss: 2.4433   \n",
      "Epoch 12/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.3837Epoch 00011: loss improved from 2.44335 to 2.38368, saving model to montypython/life-of-brian.txtweights-lstm-11-2.3837.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.3837   \n",
      "Epoch 13/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.3264Epoch 00012: loss improved from 2.38368 to 2.32639, saving model to montypython/life-of-brian.txtweights-lstm-12-2.3264.hdf5\n",
      "86950/86950 [==============================] - 106s - loss: 2.3264   \n",
      "Epoch 14/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.2837Epoch 00013: loss improved from 2.32639 to 2.28376, saving model to montypython/life-of-brian.txtweights-lstm-13-2.2838.hdf5\n",
      "86950/86950 [==============================] - 106s - loss: 2.2838   \n",
      "Epoch 15/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.2491Epoch 00014: loss improved from 2.28376 to 2.24922, saving model to montypython/life-of-brian.txtweights-lstm-14-2.2492.hdf5\n",
      "86950/86950 [==============================] - 106s - loss: 2.2492   \n",
      "Epoch 16/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.2119Epoch 00015: loss improved from 2.24922 to 2.21190, saving model to montypython/life-of-brian.txtweights-lstm-15-2.2119.hdf5\n",
      "86950/86950 [==============================] - 106s - loss: 2.2119   \n",
      "Epoch 17/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.1753Epoch 00016: loss improved from 2.21190 to 2.17531, saving model to montypython/life-of-brian.txtweights-lstm-16-2.1753.hdf5\n",
      "86950/86950 [==============================] - 107s - loss: 2.1753   \n",
      "Epoch 18/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.1402Epoch 00017: loss improved from 2.17531 to 2.14037, saving model to montypython/life-of-brian.txtweights-lstm-17-2.1404.hdf5\n",
      "86950/86950 [==============================] - 106s - loss: 2.1404   \n",
      "Epoch 19/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.1107Epoch 00018: loss improved from 2.14037 to 2.11075, saving model to montypython/life-of-brian.txtweights-lstm-18-2.1107.hdf5\n",
      "86950/86950 [==============================] - 108s - loss: 2.1107   \n",
      "Epoch 20/20\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.0755Epoch 00019: loss improved from 2.11075 to 2.07538, saving model to montypython/life-of-brian.txtweights-lstm-19-2.0754.hdf5\n",
      "86950/86950 [==============================] - 111s - loss: 2.0754   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6154a3a490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "lstmmodel.fit(X, y, nb_epoch=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \n",
      "frign oo the rooan \n",
      "rorp: the sese a sood oo the mooe oo \n",
      "brian: ihn  no  woe rooa oo the goor  and no'so \n",
      "brian: what?\n",
      "brian: io,  ren. silate  and ne' tea...\n",
      "\n",
      "brian: what?\n",
      "minate: what?\n",
      "menas #2: yhul  wiu  ant ii's sere th te tor oo the toon toe broan. shen so the rooans.\n",
      "brian: ihn  oo  noe tooen  so hene  an an a gan  .rian.  rie noot neee  sha tea  ro, no. no. \n",
      "ren: fillowers: hhh  oer: mn  she  oo  no. no. io. conen: oh, yeal, thet' aen' whu.\n",
      "milate: what?\n",
      "brian: io,  ren. oilate: whal?\n",
      "brian: i wasn to he to hot to the boonn. brian. brian. brian. brian! brian! arian!  roen' she kanter on the moont \n",
      "brian: i man tiin tou to tou tou tou \n",
      "brian: i was aot you to note to the moon  brian: ihn  oo  iiee yeu.\n",
      "mendy: whal?\n",
      "brian: io'  rer. pilate: whal?\n",
      "brian: io'  ren. pilate: whal?\n",
      "brian: io'  rer. pilate: whal?\n",
      "brian: io'  ren. pilate: whal?\n",
      "brian: io'  ren. pilate: whal?\n",
      "brian: io'  ren. pilate: whal?\n",
      "brian: io'  ren. pilate: whal?\n",
      "brian: io'  ren. pilate: whal?\n",
      "brian: io'  ren. pi\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "lstmloadedmodel = Sequential()\n",
    "lstmloadedmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "lstmloadedmodel.add(Dropout(0.2))\n",
    "lstmloadedmodel.add(Dense(y.shape[1], activation='softmax'))\n",
    "strseedpattern = \"all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \"\n",
    "print \"seed: \" + strseedpattern\n",
    "generateText(lstmloadedmodel, \"montypython/life-of-brian.txtweights-lstm-19-2.0754.hdf5\", getIntVals(strseedpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_11 (LSTM)                   (None, 100, 256)      264192      lstm_input_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 100, 256)      0           lstm_11[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                   (None, 256)           525312      dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 256)           0           lstm_12[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 49)            12593       dropout_14[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 802,097\n",
      "Trainable params: 802,097\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Define stacked LSTM\n",
    "stackedlstmmodel = Sequential()\n",
    "stackedlstmmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "stackedlstmmodel.add(Dropout(0.2))\n",
    "#Second layer of LSTM\n",
    "stackedlstmmodel.add(LSTM(256))\n",
    "stackedlstmmodel.add(Dropout(0.2))\n",
    "stackedlstmmodel.add(Dense(y.shape[1], activation='softmax'))\n",
    "stackedlstmmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "stackedlstmmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=filename+\"weights-lstmstacked-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 3.1022Epoch 00000: loss improved from inf to 3.10222, saving model to montypython/life-of-brian.txtweights-lstmstacked-00-3.1022-bigger.hdf5\n",
      "86950/86950 [==============================] - 389s - loss: 3.1022   \n",
      "Epoch 2/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.7949Epoch 00001: loss improved from 3.10222 to 2.79485, saving model to montypython/life-of-brian.txtweights-lstmstacked-01-2.7948-bigger.hdf5\n",
      "86950/86950 [==============================] - 390s - loss: 2.7948   \n",
      "Epoch 3/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.5954Epoch 00002: loss improved from 2.79485 to 2.59546, saving model to montypython/life-of-brian.txtweights-lstmstacked-02-2.5955-bigger.hdf5\n",
      "86950/86950 [==============================] - 394s - loss: 2.5955   \n",
      "Epoch 4/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.4415Epoch 00003: loss improved from 2.59546 to 2.44148, saving model to montypython/life-of-brian.txtweights-lstmstacked-03-2.4415-bigger.hdf5\n",
      "86950/86950 [==============================] - 394s - loss: 2.4415   \n",
      "Epoch 5/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.3105Epoch 00004: loss improved from 2.44148 to 2.31061, saving model to montypython/life-of-brian.txtweights-lstmstacked-04-2.3106-bigger.hdf5\n",
      "86950/86950 [==============================] - 395s - loss: 2.3106   \n",
      "Epoch 6/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.2066Epoch 00005: loss improved from 2.31061 to 2.20651, saving model to montypython/life-of-brian.txtweights-lstmstacked-05-2.2065-bigger.hdf5\n",
      "86950/86950 [==============================] - 396s - loss: 2.2065   \n",
      "Epoch 7/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.1215Epoch 00006: loss improved from 2.20651 to 2.12164, saving model to montypython/life-of-brian.txtweights-lstmstacked-06-2.1216-bigger.hdf5\n",
      "86950/86950 [==============================] - 394s - loss: 2.1216   \n",
      "Epoch 8/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 2.0532Epoch 00007: loss improved from 2.12164 to 2.05329, saving model to montypython/life-of-brian.txtweights-lstmstacked-07-2.0533-bigger.hdf5\n",
      "86950/86950 [==============================] - 396s - loss: 2.0533   \n",
      "Epoch 9/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.9873Epoch 00008: loss improved from 2.05329 to 1.98723, saving model to montypython/life-of-brian.txtweights-lstmstacked-08-1.9872-bigger.hdf5\n",
      "86950/86950 [==============================] - 397s - loss: 1.9872   \n",
      "Epoch 10/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.9337Epoch 00009: loss improved from 1.98723 to 1.93366, saving model to montypython/life-of-brian.txtweights-lstmstacked-09-1.9337-bigger.hdf5\n",
      "86950/86950 [==============================] - 388s - loss: 1.9337   \n",
      "Epoch 11/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.8807Epoch 00010: loss improved from 1.93366 to 1.88084, saving model to montypython/life-of-brian.txtweights-lstmstacked-10-1.8808-bigger.hdf5\n",
      "86950/86950 [==============================] - 386s - loss: 1.8808   \n",
      "Epoch 12/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.8345Epoch 00011: loss improved from 1.88084 to 1.83450, saving model to montypython/life-of-brian.txtweights-lstmstacked-11-1.8345-bigger.hdf5\n",
      "86950/86950 [==============================] - 388s - loss: 1.8345   \n",
      "Epoch 13/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.7902Epoch 00012: loss improved from 1.83450 to 1.79030, saving model to montypython/life-of-brian.txtweights-lstmstacked-12-1.7903-bigger.hdf5\n",
      "86950/86950 [==============================] - 395s - loss: 1.7903   \n",
      "Epoch 14/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.7489Epoch 00013: loss improved from 1.79030 to 1.74898, saving model to montypython/life-of-brian.txtweights-lstmstacked-13-1.7490-bigger.hdf5\n",
      "86950/86950 [==============================] - 395s - loss: 1.7490   \n",
      "Epoch 15/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.7148Epoch 00014: loss improved from 1.74898 to 1.71479, saving model to montypython/life-of-brian.txtweights-lstmstacked-14-1.7148-bigger.hdf5\n",
      "86950/86950 [==============================] - 395s - loss: 1.7148   \n",
      "Epoch 16/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.6792Epoch 00015: loss improved from 1.71479 to 1.67914, saving model to montypython/life-of-brian.txtweights-lstmstacked-15-1.6791-bigger.hdf5\n",
      "86950/86950 [==============================] - 395s - loss: 1.6791   \n",
      "Epoch 17/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.6435Epoch 00016: loss improved from 1.67914 to 1.64351, saving model to montypython/life-of-brian.txtweights-lstmstacked-16-1.6435-bigger.hdf5\n",
      "86950/86950 [==============================] - 394s - loss: 1.6435   \n",
      "Epoch 18/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.6154Epoch 00017: loss improved from 1.64351 to 1.61534, saving model to montypython/life-of-brian.txtweights-lstmstacked-17-1.6153-bigger.hdf5\n",
      "86950/86950 [==============================] - 394s - loss: 1.6153   \n",
      "Epoch 19/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.5855Epoch 00018: loss improved from 1.61534 to 1.58569, saving model to montypython/life-of-brian.txtweights-lstmstacked-18-1.5857-bigger.hdf5\n",
      "86950/86950 [==============================] - 395s - loss: 1.5857   \n",
      "Epoch 20/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.5586Epoch 00019: loss improved from 1.58569 to 1.55856, saving model to montypython/life-of-brian.txtweights-lstmstacked-19-1.5586-bigger.hdf5\n",
      "86950/86950 [==============================] - 389s - loss: 1.5586   \n",
      "Epoch 21/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.5324Epoch 00020: loss improved from 1.55856 to 1.53243, saving model to montypython/life-of-brian.txtweights-lstmstacked-20-1.5324-bigger.hdf5\n",
      "86950/86950 [==============================] - 386s - loss: 1.5324   \n",
      "Epoch 22/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.5102Epoch 00021: loss improved from 1.53243 to 1.50998, saving model to montypython/life-of-brian.txtweights-lstmstacked-21-1.5100-bigger.hdf5\n",
      "86950/86950 [==============================] - 387s - loss: 1.5100   \n",
      "Epoch 23/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.4911Epoch 00022: loss improved from 1.50998 to 1.49110, saving model to montypython/life-of-brian.txtweights-lstmstacked-22-1.4911-bigger.hdf5\n",
      "86950/86950 [==============================] - 384s - loss: 1.4911   \n",
      "Epoch 24/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.4659Epoch 00023: loss improved from 1.49110 to 1.46593, saving model to montypython/life-of-brian.txtweights-lstmstacked-23-1.4659-bigger.hdf5\n",
      "86950/86950 [==============================] - 385s - loss: 1.4659   \n",
      "Epoch 25/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.4451Epoch 00024: loss improved from 1.46593 to 1.44516, saving model to montypython/life-of-brian.txtweights-lstmstacked-24-1.4452-bigger.hdf5\n",
      "86950/86950 [==============================] - 385s - loss: 1.4452   \n",
      "Epoch 26/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.4310Epoch 00025: loss improved from 1.44516 to 1.43090, saving model to montypython/life-of-brian.txtweights-lstmstacked-25-1.4309-bigger.hdf5\n",
      "86950/86950 [==============================] - 383s - loss: 1.4309   \n",
      "Epoch 27/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.4116Epoch 00026: loss improved from 1.43090 to 1.41146, saving model to montypython/life-of-brian.txtweights-lstmstacked-26-1.4115-bigger.hdf5\n",
      "86950/86950 [==============================] - 384s - loss: 1.4115   \n",
      "Epoch 28/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3935Epoch 00027: loss improved from 1.41146 to 1.39341, saving model to montypython/life-of-brian.txtweights-lstmstacked-27-1.3934-bigger.hdf5\n",
      "86950/86950 [==============================] - 385s - loss: 1.3934   \n",
      "Epoch 29/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3822Epoch 00028: loss improved from 1.39341 to 1.38208, saving model to montypython/life-of-brian.txtweights-lstmstacked-28-1.3821-bigger.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86950/86950 [==============================] - 387s - loss: 1.3821   \n",
      "Epoch 30/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3670Epoch 00029: loss improved from 1.38208 to 1.36702, saving model to montypython/life-of-brian.txtweights-lstmstacked-29-1.3670-bigger.hdf5\n",
      "86950/86950 [==============================] - 388s - loss: 1.3670   \n",
      "Epoch 31/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3510Epoch 00030: loss improved from 1.36702 to 1.35092, saving model to montypython/life-of-brian.txtweights-lstmstacked-30-1.3509-bigger.hdf5\n",
      "86950/86950 [==============================] - 385s - loss: 1.3509   \n",
      "Epoch 32/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3363Epoch 00031: loss improved from 1.35092 to 1.33632, saving model to montypython/life-of-brian.txtweights-lstmstacked-31-1.3363-bigger.hdf5\n",
      "86950/86950 [==============================] - 385s - loss: 1.3363   \n",
      "Epoch 33/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3302Epoch 00032: loss improved from 1.33632 to 1.33016, saving model to montypython/life-of-brian.txtweights-lstmstacked-32-1.3302-bigger.hdf5\n",
      "86950/86950 [==============================] - 385s - loss: 1.3302   \n",
      "Epoch 34/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3139Epoch 00033: loss improved from 1.33016 to 1.31393, saving model to montypython/life-of-brian.txtweights-lstmstacked-33-1.3139-bigger.hdf5\n",
      "86950/86950 [==============================] - 381s - loss: 1.3139   \n",
      "Epoch 35/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.3018Epoch 00034: loss improved from 1.31393 to 1.30188, saving model to montypython/life-of-brian.txtweights-lstmstacked-34-1.3019-bigger.hdf5\n",
      "86950/86950 [==============================] - 380s - loss: 1.3019   \n",
      "Epoch 36/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2983Epoch 00035: loss improved from 1.30188 to 1.29855, saving model to montypython/life-of-brian.txtweights-lstmstacked-35-1.2986-bigger.hdf5\n",
      "86950/86950 [==============================] - 381s - loss: 1.2986   \n",
      "Epoch 37/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2903Epoch 00036: loss improved from 1.29855 to 1.29030, saving model to montypython/life-of-brian.txtweights-lstmstacked-36-1.2903-bigger.hdf5\n",
      "86950/86950 [==============================] - 382s - loss: 1.2903   \n",
      "Epoch 38/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2801Epoch 00037: loss improved from 1.29030 to 1.27996, saving model to montypython/life-of-brian.txtweights-lstmstacked-37-1.2800-bigger.hdf5\n",
      "86950/86950 [==============================] - 382s - loss: 1.2800   \n",
      "Epoch 39/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2666Epoch 00038: loss improved from 1.27996 to 1.26654, saving model to montypython/life-of-brian.txtweights-lstmstacked-38-1.2665-bigger.hdf5\n",
      "86950/86950 [==============================] - 381s - loss: 1.2665   \n",
      "Epoch 40/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2585Epoch 00039: loss improved from 1.26654 to 1.25837, saving model to montypython/life-of-brian.txtweights-lstmstacked-39-1.2584-bigger.hdf5\n",
      "86950/86950 [==============================] - 381s - loss: 1.2584   \n",
      "Epoch 41/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2535Epoch 00040: loss improved from 1.25837 to 1.25342, saving model to montypython/life-of-brian.txtweights-lstmstacked-40-1.2534-bigger.hdf5\n",
      "86950/86950 [==============================] - 381s - loss: 1.2534   \n",
      "Epoch 42/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2530Epoch 00041: loss improved from 1.25342 to 1.25318, saving model to montypython/life-of-brian.txtweights-lstmstacked-41-1.2532-bigger.hdf5\n",
      "86950/86950 [==============================] - 382s - loss: 1.2532   \n",
      "Epoch 43/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2408Epoch 00042: loss improved from 1.25318 to 1.24084, saving model to montypython/life-of-brian.txtweights-lstmstacked-42-1.2408-bigger.hdf5\n",
      "86950/86950 [==============================] - 382s - loss: 1.2408   \n",
      "Epoch 44/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2418Epoch 00043: loss did not improve\n",
      "86950/86950 [==============================] - 382s - loss: 1.2417   \n",
      "Epoch 45/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2312Epoch 00044: loss improved from 1.24084 to 1.23122, saving model to montypython/life-of-brian.txtweights-lstmstacked-44-1.2312-bigger.hdf5\n",
      "86950/86950 [==============================] - 383s - loss: 1.2312   \n",
      "Epoch 46/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2267Epoch 00045: loss improved from 1.23122 to 1.22689, saving model to montypython/life-of-brian.txtweights-lstmstacked-45-1.2269-bigger.hdf5\n",
      "86950/86950 [==============================] - 383s - loss: 1.2269   \n",
      "Epoch 47/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2298Epoch 00046: loss did not improve\n",
      "86950/86950 [==============================] - 383s - loss: 1.2298   \n",
      "Epoch 48/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2174Epoch 00047: loss improved from 1.22689 to 1.21735, saving model to montypython/life-of-brian.txtweights-lstmstacked-47-1.2173-bigger.hdf5\n",
      "86950/86950 [==============================] - 381s - loss: 1.2173   \n",
      "Epoch 49/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2092Epoch 00048: loss improved from 1.21735 to 1.20912, saving model to montypython/life-of-brian.txtweights-lstmstacked-48-1.2091-bigger.hdf5\n",
      "86950/86950 [==============================] - 382s - loss: 1.2091   \n",
      "Epoch 50/50\n",
      "86912/86950 [============================>.] - ETA: 0s - loss: 1.2105Epoch 00049: loss did not improve\n",
      "86950/86950 [==============================] - 382s - loss: 1.2105   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b0074d090>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "stackedlstmmodel.fit(X, y, nb_epoch=50, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  86950\n",
      "seed: all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \n",
      "brian: ahh.\n",
      "oandy: oo, no. no. no. no. i mayen the modh the somans the soetch:\n",
      "mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oow, the messiah! the messiah! mandy: oo\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X, y, dataX, dataY, char_to_int, int_to_char = prepareData()\n",
    "strseedpattern = \"all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \"\n",
    "print \"seed: \" + strseedpattern\n",
    "generateText(stackedlstmmodel, \"montypython/life-of-brian.txtweights-lstmstacked-19-1.5586-bigger.hdf5\", getIntVals(strseedpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  86950\n",
      "seed: all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \n",
      "mandy: whlt tpophsers.\n",
      "reg: what?\n",
      "reg: yeah. teg, reg? i was to pee iim away and gollg to she frur. where was a roogher brshes.\n",
      "shepherd #1: yeah. they can seally miksle wou hot to hete fige?\n",
      "brian: what?\n",
      "brian: what?\n",
      "brian: i make to say.\n",
      "'romand  weath whoe the segit bre offl the sanitation are the froundery brian she sketch:\n",
      "crowd: laughing\n",
      "pilate: so wou're not to gond and get ott there the grems are the freen.\n",
      "crian: well, it's not a jimtleh your sandin! arthur: the shoe os tee lessiah!\n",
      "shepherd #2: yeah. i can't hear a word hor a bet on the say. there is a ban soeai to be a bit of the say, then? brean yourh: what would you are detinnt.\n",
      "harry the haggler: no, no, no, no. no. no. no. i just the big of your linht bioney brian congngts. chhhus dickus the sketch:\n",
      "crowd: laughing\n",
      "pilate: so were the mentlered are the fromings br oi the face.\n",
      "brian: well, it's not a jind to she messiah.\n",
      "siepherd #2: yeah. they're all dear a fiin on the sarinuhd of yish the eidiniogst with the soetch:\n",
      "cr\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "X, y, dataX, dataY, char_to_int, int_to_char = prepareData()\n",
    "strseedpattern = \"all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \"\n",
    "print \"seed: \" + strseedpattern\n",
    "generateText(stackedlstmmodel, \"montypython/life-of-brian.txtweights-lstmstacked-48-1.2091-bigger.hdf5\", getIntVals(strseedpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \n",
      "sartos: shlt se lotel  brian: i'l not the missiah, so  shan'm jom thet ha se have the bant rine thet  thet so nevel  ali no hte all drant mf tai lote thin the segn th liver th the roran the lirt sf line, she \n",
      "reg: ih, yeah. thet'r nose thet soeat oo the foter as an thes.\n",
      "\n",
      "rere mil te teoe to tean they  brian. i was 'rou dn these in thes, ie san gom thes thee, hh so tos toenk of eare, a ban aam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam bam\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "strseedpattern = \"all right, apart from sanitation, medicine, education, wine, what have the romans ever done for us? \"\n",
    "print strseedpattern\n",
    "bilstmmodel = Sequential()\n",
    "bilstmmodel.add(Bidirectional(LSTM(256),  input_shape=(X.shape[1], X.shape[2])))\n",
    "bilstmmodel.add(Dropout(0.2))\n",
    "bilstmmodel.add(Dense(y.shape[1], activation='softmax'))\n",
    "# X, y, dataX, dataY, char_to_int = prepareData()\n",
    "generateText(bilstmmodel, \"montypython/life-of-brian.txtweights-bilstm-219-1.6268.hdf5\", getIntVals(strseedpattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
