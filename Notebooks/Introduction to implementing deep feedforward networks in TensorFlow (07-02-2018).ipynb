{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to implementing deep feedforward networks in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "\n",
    "1) Quick introduction to TensorFlow\n",
    "\n",
    "2) Implementing a deep feedforward network in TensorFlow high-level API on the MNIST data set\n",
    "\n",
    "3) Implementing the same network in the TensorFlow low-level API on the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of neural networks based on:\n",
    "## \"Hands-On Machine Learning with Scikit-Learn & TensorFlow\"\n",
    "by Aurélien Géron\n",
    "\n",
    "Visit https://www.github.com/ageron for more materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 9: Up and Running with TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple computational graph\n",
    "\n",
    "![A simple computational graph](figures/simplecompgraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Your First Graph and Running It in a Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?? Include figure 9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction phase --- Set up a computational graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'x:0' shape=() dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution phase --- Create a session, initialize the variables, and run these through the computational graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Express the same execution phase of the program using **with** block to avoid calling Session object repeatedly, explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish default session object within the with block:\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing all variables at once can be done by adding an initialization node to the computational graph during construction phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # prepare an init node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Outside Jupyter:\n",
    "#with tf.Session() as sess:\n",
    "#    init.run() # acually initialize all the variables\n",
    "#    result = f.eval()\n",
    "\n",
    "# Inside Jupyter -- obviates the need for the with-block: \n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow programs are typically split into\n",
    "\n",
    "1) Construction phase -- which sets up the computational graph of the (ML) algorithm;\n",
    "\n",
    "2) Execution phase -- which executes the computational graph, e.g. looping through training steps consisting of\n",
    "\n",
    "    a) evaluation of model, and \n",
    "\n",
    "    b) update of parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes (e.g. variables) created in TensorFlow are automatically added to the default (computational) graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.Variable(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage multiple independent graphs by temporarily making each the default graph only while interacting (modifying) them. This can be done by using **with** block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter or Python shell workflow with repeated commands can create duplicate nodes. \n",
    "\n",
    "Solution 1: restart Jupyter kernel.\n",
    "\n",
    "Solution 2: reset default graph by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle of a Node Value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow automatically detects and evaluates first the nodes that other nodes depend on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) # 10\n",
    "    print(z.eval()) # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, the evaluations of y and z are separate runs through the computational graph. These two evaluations trace backwards through dependencies and cause the repeated evaluation of both w and x.\n",
    "\n",
    "Within a session: Node values are dropped between graph runs, except variable values are kept between graph runs.\n",
    "\n",
    "To evaluate efficiently and avoid duplicate efforts, evaluate both x and y in one graph run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val) # 10\n",
    "    print(z_val) # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow operations (ops) take any number inputs and outputs. Addition and multiplication take two inputs and make one output. Constants and variables take no inputs and are called source ops. Inputs and outputs are multidimensional arrays, i.e. tensors, that have type and shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve normal equation for California housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\hat{\\theta} = ( \\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X} \\mathbf{y}$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "display(Math(r'\\hat{\\theta} = ( \\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X} \\mathbf{y}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "\n",
    "# concatenate ones-vector to data to have bias x_0 = 1 for all data points\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data] \n",
    "\n",
    "\n",
    "# Constant node to hold data:\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\") \n",
    "\n",
    "# Constant node to hold corresponding labels/target:\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\") \n",
    "# NB: 1D array housing.target is above reshaped to column vector, and -1 means unspecified, \n",
    "# to be determined from housing.target's length and the other argument(s) of reshape.\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "\n",
    "# NB tf.matmul() is matrix multiplication operation. \n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7465141e+01],\n",
       "       [ 4.3573415e-01],\n",
       "       [ 9.3382923e-03],\n",
       "       [-1.0662201e-01],\n",
       "       [ 6.4410698e-01],\n",
       "       [-4.2513184e-06],\n",
       "       [-3.7732250e-03],\n",
       "       [-4.2664889e-01],\n",
       "       [-4.4051403e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(20640), Dimension(1)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Introduction to Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron is an artificial neuron (invented 1957 by Frank Rosenblatt), that takes inputs $x_i$, re-scales them with connection weight $w_{i,j}$ and passes them to an output unit $j$, that linearly combines the products of corresponding inputs and weights, and uses a linear threshold function to output a discrete binary. \n",
    "\n",
    "Multiple output units can compose an output layer to make as many simultaneous binary classifications. \n",
    "\n",
    "Perceptron learning rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$w_{i,j}^\\text{next step} = w_{i,j} + \\eta (y_j - \\hat{y}_j)x_i$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "display(Math(r'w_{i,j}^\\text{next step} = w_{i,j} + \\eta (y_j - \\hat{y}_j)x_i'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\\eta$ is the learning rate, $\\hat{y}_j$ is the output from output unit $j$ with respect to the specific training input vector $\\mathbf{x}$, and $y_j$ is the target output (or label) of the training input vector from the training data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linear classifier could not express the logical XOR function. (\"Perceptrons\", Minsky & Papert, 1969) Much disappointment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron and Backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs have layers of units (linear threshold units, LTUs) between the layer of input (\"passthrough\") units and the layer output units. \n",
    "\n",
    "(Technically, a feedforward neural network (FNN) with units that are not linear threshold units should not be called a multi-layer perceptron?)\n",
    "\n",
    "Input and hidden layers (but not output layer) is fully connected to the next layer. Likewise, the non-output layers all have a bias neuron. \n",
    "\n",
    "Two or more hidden layers makes an ANN into a DNN. \n",
    "\n",
    "Training MLPs was solved with the backpropagation training algorithm (Rumelhart et al., 1986; Werbos 1974). This algorithm traces backwards, from output to input, the contribution to error (or error gradient) from each connection weight.\n",
    "\n",
    "(Backpropagation == \"Gradient Descent using reverse-mode autodiff.\")\n",
    "\n",
    "Having established error gradient on all weights, a gradient descent step on all weights completes the learning step. \n",
    "\n",
    "This requires differentiable activation functions on the units, so LTUs were replaces with the logistic function. \n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1+exp(-z)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modern Multi-Layer Perceptron:\n",
    "\n",
    "![A modern Multi-Layer Perceptron](figures/modernMLP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude: The MNIST data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data set is a set of 70 000 labelled  images of hand-written digits (0 through 9). \n",
    "\n",
    "Commonly used in machine learning/image processing tutorials.\n",
    "\n",
    "The images are small (28 x 28 pixels) and monochrome, with each pixel taking a value between 0 (white) and black (255).\n",
    "\n",
    "Some examples:\n",
    "\n",
    "\n",
    "![Some MNIST examples](figures/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Chapter 3 in the \"Hands-On\" book:\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABj5JREFUeJzt3a9rlf8fxvEzGQZZGLo0hA3BWQzivzHEpha1mRRhGkyWFUG0WQXFpEFENC6IQWxD0xB/40A4gpyyoJ5P+ZZvuF/3PGdnc+d6POrlvfuAPrnD2/tsot/vd4A8e3b6AwA7Q/wQSvwQSvwQSvwQSvwQSvwQSvwQSvwQanKb7+e/E8LoTWzmD3nyQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQyjxQ6jJnf4AMKiHDx+W+5s3bxq3+/fvb/XH+T+fPn0a6c/fCp78EEr8EEr8EEr8EEr8EEr8EEr8EMo5PyPV6/Uat5cvX5bXLi8vl/urV6/KfWJiotzTefJDKPFDKPFDKPFDKPFDKPFDKEd9Y+7Xr1/lvr6+PtTPbzuO+/DhQ+O2srIy1L1HaWZmptzPnDmzTZ9kdDz5IZT4IZT4IZT4IZT4IZT4IZT4IZRz/jHXdo4/Pz9f7v1+v9z/5ddmjx071ridPXu2vHZxcbHcDx8+PNBn+pd48kMo8UMo8UMo8UMo8UMo8UMo8UMo5/xj7urVq+Xedo7ftreZnZ1t3C5cuFBee/369aHuTc2TH0KJH0KJH0KJH0KJH0KJH0KJH0I55x8Dd+/ebdyeP39eXjvs+/ht13e73cat7XcKrK2tlfvCwkK5U/Pkh1Dih1Dih1Dih1Dih1Dih1Dih1ATw76v/Ze29WbjojrH73Q6naWlpcat1+sNde+d/N7+ubm5cn///v3I7r3LbeovxZMfQokfQokfQokfQokfQokfQjnq2wXajry+fv068M+enp4u96mpqXLfs6d+fmxsbDRu379/L69t8/v376GuH2OO+oBm4odQ4odQ4odQ4odQ4odQ4odQvrp7Fzh58mS537lzp3E7f/58ee3FixfL/fjx4+XeZn19vXFbXFwsr11dXR3q3tQ8+SGU+CGU+CGU+CGU+CGU+CGU+CGU9/kZqW/fvjVuw57z//nzZ6DPFMD7/EAz8UMo8UMo8UMo8UMo8UMo8UMo7/P/z5cvX8p93759jduBAwe2+uOMjeqsvu3Xe7ftT548Kfe270FI58kPocQPocQPocQPocQPocQPocQPoWLO+W/cuFHu9+7dK/e9e/c2bocOHSqvffz4cbnvZt1ut9yvXbvWuL19+7a8dn5+fpCPxCZ58kMo8UMo8UMo8UMo8UMo8UOomKO+169fl/va2trAP/vz58/lfuXKlXK/devWwPcetbZXnZ89e1bu1XHe5GT9z+/o0aPl7pXd4XjyQyjxQyjxQyjxQyjxQyjxQyjxQ6iYc/5Rmp6eLvd/+Ry/zeXLl8u97euzK7OzsyP72bTz5IdQ4odQ4odQ4odQ4odQ4odQ4odQMef8bV8DPTU1Ve69Xq9xO3HixCAfaVucPn263B89elTu/X6/3Nt+jXbl5s2bA1/L8Dz5IZT4IZT4IZT4IZT4IZT4IZT4IVTMOf/t27fL/d27d+VefT/9xsZGeW3bWXqb5eXlcv/582fj9uPHj/LatnP6I0eOlPu5c+cG3vfv319ey2h58kMo8UMo8UMo8UMo8UMo8UOoibZXNrfYtt7sb6ysrJT70tJS41a97tvpdDofP34s91G+NruwsFDuMzMz5f7gwYNyn5ub++vPxMht6h+MJz+EEj+EEj+EEj+EEj+EEj+EEj+Ecs6/Sd1ut3Fre212dXW13F+8eFHuT58+LfdLly41bqdOnSqvPXjwYLmzKznnB5qJH0KJH0KJH0KJH0KJH0KJH0I554fx45wfaCZ+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CCV+CDW5zfeb2Ob7AQ08+SGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CHUf5Zt+b+OQHReAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fb87650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[36000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an MLP with TensorFlow's High-Level API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-level API called TF.learn. \n",
    "\n",
    "DNNClassifier makes FNN with any number of hidden layers and a softmax output layer for normalized probabilities over a set of exclusive classes.\n",
    "\n",
    "Example with two hidden layers containing 300 and 100 (ReLU) neurons, respectively, and a 10 neuron softmax output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\sigma : \\mathcal{R}^K \\rightarrow [0,1]^K$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$$\\sigma (\\mathbf{z})_j = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}\\text{  for } j=1,...,K$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "display(Math(r'\\sigma : \\mathcal{R}^K \\rightarrow [0,1]^K'))\n",
    "display(Math(r'\\sigma (\\mathbf{z})_j = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}\\text{  for } j=1,...,K')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Not explained explicitly in Chapter 10, using \n",
    "# Chapter 3 and https://github.com/ageron/handson-ml/blob/master/10_introduction_to_artificial_neural_networks.ipynb\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/xt/mlvlxq350h1946_6lvrb8l4h0000gn/T/tmpGRGGgv\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10fc30f90>, '_model_dir': '/var/folders/xt/mlvlxq350h1946_6lvrb8l4h0000gn/T/tmpGRGGgv', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': 42, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/xt/mlvlxq350h1946_6lvrb8l4h0000gn/T/tmpGRGGgv/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.4005778, step = 1\n",
      "INFO:tensorflow:global_step/sec: 278.973\n",
      "INFO:tensorflow:loss = 0.31267586, step = 101 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.356\n",
      "INFO:tensorflow:loss = 0.29636884, step = 201 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.723\n",
      "INFO:tensorflow:loss = 0.4080768, step = 301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.865\n",
      "INFO:tensorflow:loss = 0.23435771, step = 401 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.09\n",
      "INFO:tensorflow:loss = 0.2913079, step = 501 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.291\n",
      "INFO:tensorflow:loss = 0.07169643, step = 601 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.356\n",
      "INFO:tensorflow:loss = 0.14009716, step = 701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.079\n",
      "INFO:tensorflow:loss = 0.19815028, step = 801 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.527\n",
      "INFO:tensorflow:loss = 0.11660824, step = 901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.721\n",
      "INFO:tensorflow:loss = 0.24129894, step = 1001 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.857\n",
      "INFO:tensorflow:loss = 0.19023083, step = 1101 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.147\n",
      "INFO:tensorflow:loss = 0.14697056, step = 1201 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.501\n",
      "INFO:tensorflow:loss = 0.1890896, step = 1301 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.523\n",
      "INFO:tensorflow:loss = 0.06954378, step = 1401 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.707\n",
      "INFO:tensorflow:loss = 0.11753181, step = 1501 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.045\n",
      "INFO:tensorflow:loss = 0.09583752, step = 1601 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.667\n",
      "INFO:tensorflow:loss = 0.03823237, step = 1701 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.791\n",
      "INFO:tensorflow:loss = 0.15002182, step = 1801 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.322\n",
      "INFO:tensorflow:loss = 0.112414055, step = 1901 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.756\n",
      "INFO:tensorflow:loss = 0.11133062, step = 2001 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.355\n",
      "INFO:tensorflow:loss = 0.021828175, step = 2101 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.025\n",
      "INFO:tensorflow:loss = 0.022309918, step = 2201 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.329\n",
      "INFO:tensorflow:loss = 0.05583959, step = 2301 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.535\n",
      "INFO:tensorflow:loss = 0.052905086, step = 2401 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.766\n",
      "INFO:tensorflow:loss = 0.09949044, step = 2501 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.052\n",
      "INFO:tensorflow:loss = 0.05044488, step = 2601 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.336\n",
      "INFO:tensorflow:loss = 0.011002336, step = 2701 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.23\n",
      "INFO:tensorflow:loss = 0.06067799, step = 2801 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.283\n",
      "INFO:tensorflow:loss = 0.17532235, step = 2901 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.839\n",
      "INFO:tensorflow:loss = 0.016599359, step = 3001 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.948\n",
      "INFO:tensorflow:loss = 0.050229833, step = 3101 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.743\n",
      "INFO:tensorflow:loss = 0.009811628, step = 3201 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.516\n",
      "INFO:tensorflow:loss = 0.040984496, step = 3301 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.844\n",
      "INFO:tensorflow:loss = 0.22640564, step = 3401 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.374\n",
      "INFO:tensorflow:loss = 0.11032523, step = 3501 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.086\n",
      "INFO:tensorflow:loss = 0.18904746, step = 3601 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.683\n",
      "INFO:tensorflow:loss = 0.030300684, step = 3701 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.916\n",
      "INFO:tensorflow:loss = 0.009619746, step = 3801 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.058\n",
      "INFO:tensorflow:loss = 0.057061974, step = 3901 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.968\n",
      "INFO:tensorflow:loss = 0.11478825, step = 4001 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.099\n",
      "INFO:tensorflow:loss = 0.030539632, step = 4101 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.023\n",
      "INFO:tensorflow:loss = 0.054942384, step = 4201 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.35\n",
      "INFO:tensorflow:loss = 0.18744163, step = 4301 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.095\n",
      "INFO:tensorflow:loss = 0.1380551, step = 4401 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.145\n",
      "INFO:tensorflow:loss = 0.0155159235, step = 4501 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.928\n",
      "INFO:tensorflow:loss = 0.01754779, step = 4601 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.332\n",
      "INFO:tensorflow:loss = 0.009509798, step = 4701 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.695\n",
      "INFO:tensorflow:loss = 0.02467858, step = 4801 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.404\n",
      "INFO:tensorflow:loss = 0.10251294, step = 4901 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.631\n",
      "INFO:tensorflow:loss = 0.08789965, step = 5001 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.634\n",
      "INFO:tensorflow:loss = 0.010380711, step = 5101 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.224\n",
      "INFO:tensorflow:loss = 0.028989911, step = 5201 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.283\n",
      "INFO:tensorflow:loss = 0.026102195, step = 5301 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.602\n",
      "INFO:tensorflow:loss = 0.026997259, step = 5401 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.95\n",
      "INFO:tensorflow:loss = 0.018675137, step = 5501 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.533\n",
      "INFO:tensorflow:loss = 0.047280237, step = 5601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.849\n",
      "INFO:tensorflow:loss = 0.008423564, step = 5701 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.269\n",
      "INFO:tensorflow:loss = 0.007797351, step = 5801 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.56\n",
      "INFO:tensorflow:loss = 0.06397591, step = 5901 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.258\n",
      "INFO:tensorflow:loss = 0.090881824, step = 6001 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.14\n",
      "INFO:tensorflow:loss = 0.014260262, step = 6101 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.599\n",
      "INFO:tensorflow:loss = 0.016228803, step = 6201 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.256\n",
      "INFO:tensorflow:loss = 0.048095588, step = 6301 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.634\n",
      "INFO:tensorflow:loss = 0.040203236, step = 6401 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.446\n",
      "INFO:tensorflow:loss = 0.012072418, step = 6501 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.2\n",
      "INFO:tensorflow:loss = 0.013664221, step = 6601 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.263\n",
      "INFO:tensorflow:loss = 0.01638243, step = 6701 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.525\n",
      "INFO:tensorflow:loss = 0.008239056, step = 6801 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.039\n",
      "INFO:tensorflow:loss = 0.012790847, step = 6901 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.102\n",
      "INFO:tensorflow:loss = 0.021387834, step = 7001 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.839\n",
      "INFO:tensorflow:loss = 0.008367192, step = 7101 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.257\n",
      "INFO:tensorflow:loss = 0.04883387, step = 7201 (0.354 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 296.335\n",
      "INFO:tensorflow:loss = 0.009504036, step = 7301 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.274\n",
      "INFO:tensorflow:loss = 0.016978893, step = 7401 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.365\n",
      "INFO:tensorflow:loss = 0.010757222, step = 7501 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.658\n",
      "INFO:tensorflow:loss = 0.010587335, step = 7601 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.37\n",
      "INFO:tensorflow:loss = 0.005931136, step = 7701 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.206\n",
      "INFO:tensorflow:loss = 0.005197429, step = 7801 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.473\n",
      "INFO:tensorflow:loss = 0.006449755, step = 7901 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.173\n",
      "INFO:tensorflow:loss = 0.0020574287, step = 8001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.731\n",
      "INFO:tensorflow:loss = 0.006619092, step = 8101 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.433\n",
      "INFO:tensorflow:loss = 0.03500336, step = 8201 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.828\n",
      "INFO:tensorflow:loss = 0.025590505, step = 8301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.079\n",
      "INFO:tensorflow:loss = 0.005352935, step = 8401 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.446\n",
      "INFO:tensorflow:loss = 0.0057409974, step = 8501 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.262\n",
      "INFO:tensorflow:loss = 0.005307211, step = 8601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.831\n",
      "INFO:tensorflow:loss = 0.0039272737, step = 8701 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.963\n",
      "INFO:tensorflow:loss = 0.008358784, step = 8801 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.912\n",
      "INFO:tensorflow:loss = 0.0027265372, step = 8901 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.17\n",
      "INFO:tensorflow:loss = 0.0041564466, step = 9001 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.959\n",
      "INFO:tensorflow:loss = 0.008153919, step = 9101 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.473\n",
      "INFO:tensorflow:loss = 0.00431604, step = 9201 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.938\n",
      "INFO:tensorflow:loss = 0.0053035887, step = 9301 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.32\n",
      "INFO:tensorflow:loss = 0.04991601, step = 9401 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.781\n",
      "INFO:tensorflow:loss = 0.003466385, step = 9501 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.173\n",
      "INFO:tensorflow:loss = 0.022571037, step = 9601 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.854\n",
      "INFO:tensorflow:loss = 0.009801387, step = 9701 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.416\n",
      "INFO:tensorflow:loss = 0.0025435286, step = 9801 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.791\n",
      "INFO:tensorflow:loss = 0.012849368, step = 9901 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.176\n",
      "INFO:tensorflow:loss = 0.0025271494, step = 10001 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.961\n",
      "INFO:tensorflow:loss = 0.0050374116, step = 10101 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.735\n",
      "INFO:tensorflow:loss = 0.009774216, step = 10201 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.052\n",
      "INFO:tensorflow:loss = 0.0021551389, step = 10301 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.926\n",
      "INFO:tensorflow:loss = 0.003974612, step = 10401 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.281\n",
      "INFO:tensorflow:loss = 0.0045803287, step = 10501 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.412\n",
      "INFO:tensorflow:loss = 0.010262251, step = 10601 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.356\n",
      "INFO:tensorflow:loss = 0.026278675, step = 10701 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.899\n",
      "INFO:tensorflow:loss = 0.004861756, step = 10801 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.037\n",
      "INFO:tensorflow:loss = 0.0015780836, step = 10901 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.939\n",
      "INFO:tensorflow:loss = 0.0211305, step = 11001 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.924\n",
      "INFO:tensorflow:loss = 0.0032920483, step = 11101 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.75\n",
      "INFO:tensorflow:loss = 0.0009200088, step = 11201 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.979\n",
      "INFO:tensorflow:loss = 0.0067240377, step = 11301 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.974\n",
      "INFO:tensorflow:loss = 0.0052556265, step = 11401 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.901\n",
      "INFO:tensorflow:loss = 0.014270798, step = 11501 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.932\n",
      "INFO:tensorflow:loss = 0.0010388009, step = 11601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.158\n",
      "INFO:tensorflow:loss = 0.0033234973, step = 11701 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.116\n",
      "INFO:tensorflow:loss = 0.0006890038, step = 11801 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.109\n",
      "INFO:tensorflow:loss = 0.00561754, step = 11901 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.852\n",
      "INFO:tensorflow:loss = 0.00064186467, step = 12001 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.037\n",
      "INFO:tensorflow:loss = 0.0026009055, step = 12101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.484\n",
      "INFO:tensorflow:loss = 0.0028248266, step = 12201 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.015\n",
      "INFO:tensorflow:loss = 0.005670745, step = 12301 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.025\n",
      "INFO:tensorflow:loss = 0.00037431132, step = 12401 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.158\n",
      "INFO:tensorflow:loss = 0.0009724629, step = 12501 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.502\n",
      "INFO:tensorflow:loss = 0.002971116, step = 12601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.08\n",
      "INFO:tensorflow:loss = 0.0025933585, step = 12701 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.247\n",
      "INFO:tensorflow:loss = 0.013733688, step = 12801 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.055\n",
      "INFO:tensorflow:loss = 0.0031792028, step = 12901 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.528\n",
      "INFO:tensorflow:loss = 0.006552681, step = 13001 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.153\n",
      "INFO:tensorflow:loss = 0.0034216207, step = 13101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.845\n",
      "INFO:tensorflow:loss = 0.0016324178, step = 13201 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.83\n",
      "INFO:tensorflow:loss = 0.011358909, step = 13301 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.718\n",
      "INFO:tensorflow:loss = 0.005848825, step = 13401 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.678\n",
      "INFO:tensorflow:loss = 0.0029444648, step = 13501 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.242\n",
      "INFO:tensorflow:loss = 0.0054142918, step = 13601 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.684\n",
      "INFO:tensorflow:loss = 0.0021757944, step = 13701 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.121\n",
      "INFO:tensorflow:loss = 0.0069082426, step = 13801 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.533\n",
      "INFO:tensorflow:loss = 0.0046300385, step = 13901 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.031\n",
      "INFO:tensorflow:loss = 0.0021858108, step = 14001 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.749\n",
      "INFO:tensorflow:loss = 0.011085386, step = 14101 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.61\n",
      "INFO:tensorflow:loss = 0.006658467, step = 14201 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.916\n",
      "INFO:tensorflow:loss = 0.0007703595, step = 14301 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.69\n",
      "INFO:tensorflow:loss = 0.0011539387, step = 14401 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.214\n",
      "INFO:tensorflow:loss = 0.0010545183, step = 14501 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.512\n",
      "INFO:tensorflow:loss = 0.0048172306, step = 14601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.016\n",
      "INFO:tensorflow:loss = 0.0013384329, step = 14701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.776\n",
      "INFO:tensorflow:loss = 0.0011707735, step = 14801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.845\n",
      "INFO:tensorflow:loss = 0.002439394, step = 14901 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.076\n",
      "INFO:tensorflow:loss = 0.0016568727, step = 15001 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.926\n",
      "INFO:tensorflow:loss = 0.0023113445, step = 15101 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.387\n",
      "INFO:tensorflow:loss = 0.001015892, step = 15201 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0022939122, step = 15301 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.984\n",
      "INFO:tensorflow:loss = 0.0028404044, step = 15401 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.101\n",
      "INFO:tensorflow:loss = 0.005412121, step = 15501 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.4\n",
      "INFO:tensorflow:loss = 0.0035895878, step = 15601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.907\n",
      "INFO:tensorflow:loss = 0.0058891536, step = 15701 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.699\n",
      "INFO:tensorflow:loss = 0.0008186471, step = 15801 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.366\n",
      "INFO:tensorflow:loss = 0.00085781404, step = 15901 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.465\n",
      "INFO:tensorflow:loss = 0.0065113665, step = 16001 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.693\n",
      "INFO:tensorflow:loss = 0.0030622215, step = 16101 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.33\n",
      "INFO:tensorflow:loss = 0.0001887983, step = 16201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.2\n",
      "INFO:tensorflow:loss = 0.0025533608, step = 16301 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.307\n",
      "INFO:tensorflow:loss = 0.0011763193, step = 16401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.944\n",
      "INFO:tensorflow:loss = 0.0017928132, step = 16501 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.307\n",
      "INFO:tensorflow:loss = 0.0024241805, step = 16601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.423\n",
      "INFO:tensorflow:loss = 0.0024024954, step = 16701 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.953\n",
      "INFO:tensorflow:loss = 0.002722007, step = 16801 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.224\n",
      "INFO:tensorflow:loss = 0.001503015, step = 16901 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.571\n",
      "INFO:tensorflow:loss = 0.003879984, step = 17001 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.479\n",
      "INFO:tensorflow:loss = 0.0028237433, step = 17101 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.089\n",
      "INFO:tensorflow:loss = 0.0022598186, step = 17201 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.302\n",
      "INFO:tensorflow:loss = 0.0011070793, step = 17301 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.922\n",
      "INFO:tensorflow:loss = 0.0013992988, step = 17401 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.238\n",
      "INFO:tensorflow:loss = 0.0016118982, step = 17501 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.654\n",
      "INFO:tensorflow:loss = 0.0008287414, step = 17601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.633\n",
      "INFO:tensorflow:loss = 0.0010201752, step = 17701 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.919\n",
      "INFO:tensorflow:loss = 0.00018981178, step = 17801 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.731\n",
      "INFO:tensorflow:loss = 0.0020044565, step = 17901 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.055\n",
      "INFO:tensorflow:loss = 0.00046436657, step = 18001 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.533\n",
      "INFO:tensorflow:loss = 0.00092771056, step = 18101 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.939\n",
      "INFO:tensorflow:loss = 0.0036528863, step = 18201 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.057\n",
      "INFO:tensorflow:loss = 0.005607925, step = 18301 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.265\n",
      "INFO:tensorflow:loss = 0.0026073065, step = 18401 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.791\n",
      "INFO:tensorflow:loss = 0.0052851615, step = 18501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.708\n",
      "INFO:tensorflow:loss = 0.0038767403, step = 18601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.191\n",
      "INFO:tensorflow:loss = 0.0017031265, step = 18701 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.556\n",
      "INFO:tensorflow:loss = 0.0020837628, step = 18801 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.258\n",
      "INFO:tensorflow:loss = 0.0026109123, step = 18901 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.185\n",
      "INFO:tensorflow:loss = 0.0014386168, step = 19001 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.433\n",
      "INFO:tensorflow:loss = 0.0005016105, step = 19101 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.103\n",
      "INFO:tensorflow:loss = 0.0011798079, step = 19201 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.369\n",
      "INFO:tensorflow:loss = 0.0056989426, step = 19301 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.858\n",
      "INFO:tensorflow:loss = 0.0014174287, step = 19401 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.909\n",
      "INFO:tensorflow:loss = 0.00181431, step = 19501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.871\n",
      "INFO:tensorflow:loss = 0.00072336383, step = 19601 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.664\n",
      "INFO:tensorflow:loss = 9.478824e-05, step = 19701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.461\n",
      "INFO:tensorflow:loss = 0.00046725423, step = 19801 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.224\n",
      "INFO:tensorflow:loss = 0.0019611202, step = 19901 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.109\n",
      "INFO:tensorflow:loss = 0.0025471402, step = 20001 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.192\n",
      "INFO:tensorflow:loss = 0.00043874516, step = 20101 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.466\n",
      "INFO:tensorflow:loss = 0.0025391192, step = 20201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.599\n",
      "INFO:tensorflow:loss = 0.0010329548, step = 20301 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.689\n",
      "INFO:tensorflow:loss = 0.00016640488, step = 20401 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.081\n",
      "INFO:tensorflow:loss = 0.0009935172, step = 20501 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.156\n",
      "INFO:tensorflow:loss = 0.0008639615, step = 20601 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.3\n",
      "INFO:tensorflow:loss = 0.00084766647, step = 20701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.746\n",
      "INFO:tensorflow:loss = 0.0010883757, step = 20801 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.096\n",
      "INFO:tensorflow:loss = 0.0015062927, step = 20901 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.389\n",
      "INFO:tensorflow:loss = 0.0022610624, step = 21001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.463\n",
      "INFO:tensorflow:loss = 0.0010078625, step = 21101 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.217\n",
      "INFO:tensorflow:loss = 0.00453955, step = 21201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.878\n",
      "INFO:tensorflow:loss = 0.0005150675, step = 21301 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.053\n",
      "INFO:tensorflow:loss = 0.002108911, step = 21401 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.046\n",
      "INFO:tensorflow:loss = 0.0003527573, step = 21501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.044\n",
      "INFO:tensorflow:loss = 0.0007121074, step = 21601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.918\n",
      "INFO:tensorflow:loss = 0.0009194807, step = 21701 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.673\n",
      "INFO:tensorflow:loss = 0.000383486, step = 21801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.509\n",
      "INFO:tensorflow:loss = 0.0004972108, step = 21901 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.823\n",
      "INFO:tensorflow:loss = 6.2377825e-05, step = 22001 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.825\n",
      "INFO:tensorflow:loss = 0.0002139326, step = 22101 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.77\n",
      "INFO:tensorflow:loss = 0.0011587589, step = 22201 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.826\n",
      "INFO:tensorflow:loss = 0.0015314096, step = 22301 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.174\n",
      "INFO:tensorflow:loss = 0.0019228004, step = 22401 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.684\n",
      "INFO:tensorflow:loss = 0.0013467915, step = 22501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.571\n",
      "INFO:tensorflow:loss = 0.0023154982, step = 22601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.547\n",
      "INFO:tensorflow:loss = 0.00090699946, step = 22701 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.169\n",
      "INFO:tensorflow:loss = 0.0008416923, step = 22801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.143\n",
      "INFO:tensorflow:loss = 0.0020299358, step = 22901 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.757\n",
      "INFO:tensorflow:loss = 0.00051947305, step = 23001 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.987\n",
      "INFO:tensorflow:loss = 0.0023677696, step = 23101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.419\n",
      "INFO:tensorflow:loss = 0.0018610213, step = 23201 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0018711936, step = 23301 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.893\n",
      "INFO:tensorflow:loss = 0.0005051533, step = 23401 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.813\n",
      "INFO:tensorflow:loss = 0.00076665386, step = 23501 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.564\n",
      "INFO:tensorflow:loss = 0.000556651, step = 23601 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.759\n",
      "INFO:tensorflow:loss = 0.0001052184, step = 23701 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.798\n",
      "INFO:tensorflow:loss = 0.00091980194, step = 23801 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.882\n",
      "INFO:tensorflow:loss = 0.0017980053, step = 23901 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.248\n",
      "INFO:tensorflow:loss = 0.0014662343, step = 24001 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.85\n",
      "INFO:tensorflow:loss = 0.0006457205, step = 24101 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.761\n",
      "INFO:tensorflow:loss = 0.0017085895, step = 24201 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.196\n",
      "INFO:tensorflow:loss = 0.00019012339, step = 24301 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.853\n",
      "INFO:tensorflow:loss = 0.0018188378, step = 24401 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.783\n",
      "INFO:tensorflow:loss = 0.0012226698, step = 24501 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.547\n",
      "INFO:tensorflow:loss = 0.00072973536, step = 24601 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.998\n",
      "INFO:tensorflow:loss = 0.0011833684, step = 24701 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.72\n",
      "INFO:tensorflow:loss = 0.0011878891, step = 24801 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.504\n",
      "INFO:tensorflow:loss = 0.0013818216, step = 24901 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.227\n",
      "INFO:tensorflow:loss = 0.00048778497, step = 25001 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.201\n",
      "INFO:tensorflow:loss = 0.00084742083, step = 25101 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.589\n",
      "INFO:tensorflow:loss = 0.0016339379, step = 25201 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.56\n",
      "INFO:tensorflow:loss = 0.00015762541, step = 25301 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.251\n",
      "INFO:tensorflow:loss = 0.00057926326, step = 25401 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.149\n",
      "INFO:tensorflow:loss = 0.00096197583, step = 25501 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.579\n",
      "INFO:tensorflow:loss = 0.00072867685, step = 25601 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.637\n",
      "INFO:tensorflow:loss = 0.0003659475, step = 25701 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.38\n",
      "INFO:tensorflow:loss = 0.0006396459, step = 25801 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.927\n",
      "INFO:tensorflow:loss = 0.0014290272, step = 25901 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.689\n",
      "INFO:tensorflow:loss = 0.00010238056, step = 26001 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.912\n",
      "INFO:tensorflow:loss = 0.0007521265, step = 26101 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.128\n",
      "INFO:tensorflow:loss = 0.0011646885, step = 26201 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.381\n",
      "INFO:tensorflow:loss = 0.0007397069, step = 26301 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.607\n",
      "INFO:tensorflow:loss = 0.0011290793, step = 26401 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.19\n",
      "INFO:tensorflow:loss = 0.00079500815, step = 26501 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.451\n",
      "INFO:tensorflow:loss = 0.00047347747, step = 26601 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.433\n",
      "INFO:tensorflow:loss = 3.1328407e-05, step = 26701 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.291\n",
      "INFO:tensorflow:loss = 0.00035584634, step = 26801 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.261\n",
      "INFO:tensorflow:loss = 0.0007996074, step = 26901 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.712\n",
      "INFO:tensorflow:loss = 0.00077521073, step = 27001 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.801\n",
      "INFO:tensorflow:loss = 0.00047619123, step = 27101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.924\n",
      "INFO:tensorflow:loss = 0.00039861762, step = 27201 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.704\n",
      "INFO:tensorflow:loss = 0.0011550712, step = 27301 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.071\n",
      "INFO:tensorflow:loss = 0.0005360307, step = 27401 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.148\n",
      "INFO:tensorflow:loss = 0.0010285559, step = 27501 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.219\n",
      "INFO:tensorflow:loss = 0.0011170513, step = 27601 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.359\n",
      "INFO:tensorflow:loss = 0.00024562303, step = 27701 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.809\n",
      "INFO:tensorflow:loss = 0.00017662946, step = 27801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.292\n",
      "INFO:tensorflow:loss = 0.00060662144, step = 27901 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.296\n",
      "INFO:tensorflow:loss = 0.0014573914, step = 28001 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.678\n",
      "INFO:tensorflow:loss = 0.00066597166, step = 28101 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.459\n",
      "INFO:tensorflow:loss = 0.0007559935, step = 28201 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.244\n",
      "INFO:tensorflow:loss = 0.00081949023, step = 28301 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.886\n",
      "INFO:tensorflow:loss = 0.0012622013, step = 28401 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.5\n",
      "INFO:tensorflow:loss = 0.00015271838, step = 28501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.056\n",
      "INFO:tensorflow:loss = 0.0005445875, step = 28601 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.059\n",
      "INFO:tensorflow:loss = 0.001242336, step = 28701 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.912\n",
      "INFO:tensorflow:loss = 0.0011522959, step = 28801 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.661\n",
      "INFO:tensorflow:loss = 0.00029501267, step = 28901 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.689\n",
      "INFO:tensorflow:loss = 0.0012439629, step = 29001 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.078\n",
      "INFO:tensorflow:loss = 0.0011318299, step = 29101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.881\n",
      "INFO:tensorflow:loss = 0.0011576376, step = 29201 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.855\n",
      "INFO:tensorflow:loss = 0.0012464767, step = 29301 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.057\n",
      "INFO:tensorflow:loss = 0.0011650472, step = 29401 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.535\n",
      "INFO:tensorflow:loss = 0.00089854986, step = 29501 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.455\n",
      "INFO:tensorflow:loss = 0.0003493056, step = 29601 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.052\n",
      "INFO:tensorflow:loss = 0.0001967982, step = 29701 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.059\n",
      "INFO:tensorflow:loss = 0.00042677126, step = 29801 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.3\n",
      "INFO:tensorflow:loss = 0.00096111797, step = 29901 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.458\n",
      "INFO:tensorflow:loss = 0.00018180076, step = 30001 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.601\n",
      "INFO:tensorflow:loss = 0.0005855758, step = 30101 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.702\n",
      "INFO:tensorflow:loss = 0.00021347596, step = 30201 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.265\n",
      "INFO:tensorflow:loss = 0.00061550434, step = 30301 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.019\n",
      "INFO:tensorflow:loss = 0.0015167601, step = 30401 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.422\n",
      "INFO:tensorflow:loss = 0.0007232324, step = 30501 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.786\n",
      "INFO:tensorflow:loss = 0.00081983523, step = 30601 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.785\n",
      "INFO:tensorflow:loss = 0.0006647414, step = 30701 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.8\n",
      "INFO:tensorflow:loss = 0.0010431712, step = 30801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.172\n",
      "INFO:tensorflow:loss = 0.0005624868, step = 30901 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.972\n",
      "INFO:tensorflow:loss = 0.00092834665, step = 31001 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.964\n",
      "INFO:tensorflow:loss = 0.0011234849, step = 31101 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.645\n",
      "INFO:tensorflow:loss = 0.00031862652, step = 31201 (0.347 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 300.455\n",
      "INFO:tensorflow:loss = 0.0004291339, step = 31301 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.231\n",
      "INFO:tensorflow:loss = 0.0013877174, step = 31401 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.073\n",
      "INFO:tensorflow:loss = 0.00020001482, step = 31501 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.374\n",
      "INFO:tensorflow:loss = 0.00032674294, step = 31601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.03\n",
      "INFO:tensorflow:loss = 0.0006365755, step = 31701 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.931\n",
      "INFO:tensorflow:loss = 0.00016916303, step = 31801 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.385\n",
      "INFO:tensorflow:loss = 0.0006920603, step = 31901 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.666\n",
      "INFO:tensorflow:loss = 0.00012926888, step = 32001 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.248\n",
      "INFO:tensorflow:loss = 0.00039280686, step = 32101 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.539\n",
      "INFO:tensorflow:loss = 0.0011558913, step = 32201 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.446\n",
      "INFO:tensorflow:loss = 0.00056561973, step = 32301 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.852\n",
      "INFO:tensorflow:loss = 0.00017675917, step = 32401 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.822\n",
      "INFO:tensorflow:loss = 0.00040773995, step = 32501 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.632\n",
      "INFO:tensorflow:loss = 0.00021993961, step = 32601 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.738\n",
      "INFO:tensorflow:loss = 0.00079787505, step = 32701 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.106\n",
      "INFO:tensorflow:loss = 0.00090279884, step = 32801 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.829\n",
      "INFO:tensorflow:loss = 0.0005482138, step = 32901 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.159\n",
      "INFO:tensorflow:loss = 0.0006554589, step = 33001 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.558\n",
      "INFO:tensorflow:loss = 0.0018582876, step = 33101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.79\n",
      "INFO:tensorflow:loss = 0.00076735055, step = 33201 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.435\n",
      "INFO:tensorflow:loss = 0.00038163952, step = 33301 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.57\n",
      "INFO:tensorflow:loss = 0.001371027, step = 33401 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.625\n",
      "INFO:tensorflow:loss = 0.00029575542, step = 33501 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.978\n",
      "INFO:tensorflow:loss = 0.00088878634, step = 33601 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.22\n",
      "INFO:tensorflow:loss = 0.0009937927, step = 33701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.106\n",
      "INFO:tensorflow:loss = 0.0005908036, step = 33801 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.938\n",
      "INFO:tensorflow:loss = 0.0009054421, step = 33901 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.994\n",
      "INFO:tensorflow:loss = 0.00071158016, step = 34001 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.86\n",
      "INFO:tensorflow:loss = 0.00053563213, step = 34101 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.807\n",
      "INFO:tensorflow:loss = 0.0011523266, step = 34201 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.049\n",
      "INFO:tensorflow:loss = 0.00016720987, step = 34301 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.433\n",
      "INFO:tensorflow:loss = 0.0004537905, step = 34401 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.662\n",
      "INFO:tensorflow:loss = 0.00044780105, step = 34501 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.467\n",
      "INFO:tensorflow:loss = 0.00041601766, step = 34601 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.247\n",
      "INFO:tensorflow:loss = 0.0011050355, step = 34701 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.6\n",
      "INFO:tensorflow:loss = 0.00052697194, step = 34801 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.631\n",
      "INFO:tensorflow:loss = 0.00071083516, step = 34901 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.047\n",
      "INFO:tensorflow:loss = 0.0002585916, step = 35001 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.897\n",
      "INFO:tensorflow:loss = 0.0008163878, step = 35101 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.564\n",
      "INFO:tensorflow:loss = 0.00018969526, step = 35201 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.271\n",
      "INFO:tensorflow:loss = 0.0001349323, step = 35301 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.269\n",
      "INFO:tensorflow:loss = 0.0010902109, step = 35401 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.349\n",
      "INFO:tensorflow:loss = 0.00035070805, step = 35501 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.473\n",
      "INFO:tensorflow:loss = 0.0002819493, step = 35601 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.428\n",
      "INFO:tensorflow:loss = 0.0008391325, step = 35701 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.59\n",
      "INFO:tensorflow:loss = 0.000632369, step = 35801 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.59\n",
      "INFO:tensorflow:loss = 0.00037967376, step = 35901 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.301\n",
      "INFO:tensorflow:loss = 0.0003320363, step = 36001 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.489\n",
      "INFO:tensorflow:loss = 0.0011039884, step = 36101 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.686\n",
      "INFO:tensorflow:loss = 0.0008606437, step = 36201 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.183\n",
      "INFO:tensorflow:loss = 0.0002927651, step = 36301 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.162\n",
      "INFO:tensorflow:loss = 0.00069891097, step = 36401 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.267\n",
      "INFO:tensorflow:loss = 0.00015776746, step = 36501 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.217\n",
      "INFO:tensorflow:loss = 0.00033270434, step = 36601 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.535\n",
      "INFO:tensorflow:loss = 0.00028696892, step = 36701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.918\n",
      "INFO:tensorflow:loss = 0.0008025733, step = 36801 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.476\n",
      "INFO:tensorflow:loss = 0.0005028858, step = 36901 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.332\n",
      "INFO:tensorflow:loss = 0.00062359317, step = 37001 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.646\n",
      "INFO:tensorflow:loss = 0.00019955178, step = 37101 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.333\n",
      "INFO:tensorflow:loss = 0.00016318852, step = 37201 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.327\n",
      "INFO:tensorflow:loss = 0.0006694493, step = 37301 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.407\n",
      "INFO:tensorflow:loss = 0.0003708102, step = 37401 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.893\n",
      "INFO:tensorflow:loss = 0.00025077042, step = 37501 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.425\n",
      "INFO:tensorflow:loss = 0.000264987, step = 37601 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.189\n",
      "INFO:tensorflow:loss = 0.00010086442, step = 37701 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.428\n",
      "INFO:tensorflow:loss = 0.0006153757, step = 37801 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.597\n",
      "INFO:tensorflow:loss = 0.0011952921, step = 37901 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.187\n",
      "INFO:tensorflow:loss = 0.00019914961, step = 38001 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.375\n",
      "INFO:tensorflow:loss = 0.0008874108, step = 38101 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.819\n",
      "INFO:tensorflow:loss = 0.00077106326, step = 38201 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.706\n",
      "INFO:tensorflow:loss = 5.9410097e-05, step = 38301 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.701\n",
      "INFO:tensorflow:loss = 0.000106180356, step = 38401 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.356\n",
      "INFO:tensorflow:loss = 0.0004074581, step = 38501 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.547\n",
      "INFO:tensorflow:loss = 0.0006691146, step = 38601 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.467\n",
      "INFO:tensorflow:loss = 0.00045461592, step = 38701 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.239\n",
      "INFO:tensorflow:loss = 0.00013856331, step = 38801 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.566\n",
      "INFO:tensorflow:loss = 0.0014249012, step = 38901 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.685\n",
      "INFO:tensorflow:loss = 0.0001628006, step = 39001 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.565\n",
      "INFO:tensorflow:loss = 0.0007085502, step = 39101 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00033850258, step = 39201 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.42\n",
      "INFO:tensorflow:loss = 0.00038915616, step = 39301 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.976\n",
      "INFO:tensorflow:loss = 0.0003968734, step = 39401 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.761\n",
      "INFO:tensorflow:loss = 0.00015025295, step = 39501 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.344\n",
      "INFO:tensorflow:loss = 0.00062390114, step = 39601 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.192\n",
      "INFO:tensorflow:loss = 0.00014465627, step = 39701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.085\n",
      "INFO:tensorflow:loss = 0.0011388173, step = 39801 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.093\n",
      "INFO:tensorflow:loss = 0.0007998731, step = 39901 (0.367 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /var/folders/xt/mlvlxq350h1946_6lvrb8l4h0000gn/T/tmpGRGGgv/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00044029002.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuing with DNN, from Chapter 10:\n",
    "import tensorflow as tf\n",
    "\n",
    "# From github.com/ageron ch 10 notebook: {\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42)\n",
    "# }\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10, \n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/xt/mlvlxq350h1946_6lvrb8l4h0000gn/T/tmpGRGGgv/model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9835"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: clf stands for classifier. Common in sklearn and tensorflow example code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN Using Plain TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower-level Python API, gives more control. \n",
    "\n",
    "Same model as before, with Mini-Batch Gradient Descent to train on the MNIST data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "n_inputs = 28*28 # MNIST \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\") # None: We don't know size of training set/batch. \n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\") # Ditto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$ acts as input layer and will be iteratively replaced by training batches. \n",
    "\n",
    "Define function for creating subsequent layers, one at a time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1]) # Get the number of columns in X, i.e. dimension of each input vector. \n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b # broadcasting: b is added to every *row* of matrix tf.matmul(X, W).\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name_scope is useful for organizing the visualization of the graph using TensorBoard.\n",
    "\n",
    "$W$ is the weights matrix, or \"kernel\", for all the connection weights between inputs (previous layer units?) and neurons in the layer here being defined. \n",
    "\n",
    "Weights are initialized randomly from a truncated normal distribution with standard deviation $\\frac{2}{\\sqrt{n_\\text{inputs}}}$. Randomization helps avoid unbreakable symmetry.\n",
    "\n",
    "Bias initialized to $0$, as it has no symmetry issues. \n",
    "\n",
    "Activation parameter could be provided, such as tf.nn.relu.\n",
    "\n",
    "Creating neuron layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\") # before Softmax, to be handled later for optimization reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, use pre-defined TensorFlow function tf.layers.dense():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\") # before Softmax, to be handled later for optimization reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax output lends itself to training with a cross entropy cost function. If the classifier model assigns low probability to the correct class, the cross entropy cost function penalizes the model. \n",
    "\n",
    "The built-in TensorFlow function sparse_softmax_cross_entropy_with_logits() assumes logits as output from network before passing to softmax activation function. \n",
    "   - Labels are expected in the form $y \\in \\{ 0,1,...,(n_\\text{classes}-1) \\}$. \n",
    "   - The function returns a 1D tensor with cross entropy for each training input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\") # Get mean cross entropy over all training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32)) # Cast Boolean True/False values as float to take the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() # Saving trained model parameters to disk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Phases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, ' Train accuracy: ', 0.92, ' Test accuracy: ', 0.9006)\n",
      "(1, ' Train accuracy: ', 0.86, ' Test accuracy: ', 0.919)\n",
      "(2, ' Train accuracy: ', 0.94, ' Test accuracy: ', 0.9296)\n",
      "(3, ' Train accuracy: ', 0.94, ' Test accuracy: ', 0.9363)\n",
      "(4, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9406)\n",
      "(5, ' Train accuracy: ', 0.92, ' Test accuracy: ', 0.9463)\n",
      "(6, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9506)\n",
      "(7, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9527)\n",
      "(8, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9556)\n",
      "(9, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.958)\n",
      "(10, ' Train accuracy: ', 0.92, ' Test accuracy: ', 0.9605)\n",
      "(11, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9639)\n",
      "(12, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9644)\n",
      "(13, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9659)\n",
      "(14, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9666)\n",
      "(15, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9681)\n",
      "(16, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9679)\n",
      "(17, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9697)\n",
      "(18, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9705)\n",
      "(19, ' Train accuracy: ', 0.94, ' Test accuracy: ', 0.9708)\n",
      "(20, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9713)\n",
      "(21, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9723)\n",
      "(22, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9727)\n",
      "(23, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9739)\n",
      "(24, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9734)\n",
      "(25, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9735)\n",
      "(26, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9743)\n",
      "(27, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9744)\n",
      "(28, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.975)\n",
      "(29, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.975)\n",
      "(30, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.976)\n",
      "(31, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9752)\n",
      "(32, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9756)\n",
      "(33, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9761)\n",
      "(34, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.976)\n",
      "(35, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9769)\n",
      "(36, ' Train accuracy: ', 0.98, ' Test accuracy: ', 0.9765)\n",
      "(37, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9765)\n",
      "(38, ' Train accuracy: ', 0.96, ' Test accuracy: ', 0.9773)\n",
      "(39, ' Train accuracy: ', 1.0, ' Test accuracy: ', 0.9762)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \" Train accuracy: \", acc_train, \" Test accuracy: \", acc_test)\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-87a8ab509a3e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-87a8ab509a3e>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    X_new_scaled = [...] # some new images (scaled from 0 to 1)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    X_new_scaled = [...] # some new images (scaled from 0 to 1)\n",
    "    Z = logits.eval(feed_dict={X_ X_new_scaled}) \n",
    "    y_pred = np.argmax(Z, axis=1) \n",
    "# NB: Here passing logits to argmax instead of softmax to get the best label \n",
    "# instead of the normalized probabilities of all classes wrt the input vector(s) in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-use the construction phase code, but replace execution phase code with the above (inserting new data in X_new_scaled variable) to use the trained model as a classifier on new data. \n",
    "\n",
    "Would need to find, ingest, re-scale some 28x28 pixel image(s). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Summary\n",
    "\n",
    "2) Discussion points:\n",
    "    - Fine-tuning hyperparameters: \n",
    "        - Network topology\n",
    "        - Number of layers \n",
    "            parameter efficiency: deeper nets can model complex functions with fewer neurons than shallow nets.\n",
    "        - Number of neurons per layer\n",
    "            (A) Funnel many lower-level features into fewer higher-level features.\n",
    "            (B) All hidden layers same width.\n",
    "                    Start with a wide (and deep) enough network, then trim down to optimize.\n",
    "        - Activation functions\n",
    "            Output suggestion: Softmax for a set of mutually exclusive classes, sigmoid for non-exclusive.\n",
    "                For regression: No activation on output layer. \n",
    "        - Weight initialization\n",
    "        - ++\n",
    "    - Strategies: grid search, randomized search, specialized optimization tools.\n",
    "\n",
    "3) Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
